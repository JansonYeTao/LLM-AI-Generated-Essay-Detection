# LLM-AI-Generated-Essay-Detection


# LLM Generated Text Detection

- https://www.kaggle.com/competitions/llm-detect-ai-generated-text/overview


# Train & Test Data Description:


The competition dataset comprises about 10,000 essays, some written by students and some generated by a variety of large language models (LLMs). The goal of the competition is to determine whether or not essay was generated by an LLM.

All of the essays were written in response to one of seven essay prompts. In each prompt, the students were instructed to read one or more source texts and then write a response. This same information may or may not have been provided as input to an LLM when generating an essay.

Essays from two of the prompts compose the training set; the remaining essays compose the hidden test set. Nearly all of the training set essays were written by students, with only a few generated essays given as examples. You may wish to generate more essays to use as training data.

Please note that this is a Code Competition. The data in test_essays.csv is only dummy data to help you author your solutions. When your submission is scored, this example test data will be replaced with the full test set. There are about 9,000 essays in the test set, both student written and LLM generated.

>
> **ATTENTION**: Folks report that train and test data come from persuade corpus2 and this was shared at discussion threads:
> - https://www.kaggle.com/competitions/llm-detect-ai-generated-text/discussion/453410
> - https://www.kaggle.com/datasets/nbroad/persaude-corpus-2
> - https://www.kaggle.com/code/nbroad/persuade-train-essays-analysis
> - https://www.kaggle.com/code/nbroad/persuade-train-essays-analysis/notebook
  

<br>

https://www.kaggle.com/competitions/llm-detect-ai-generated-text/discussion/453410

This leaderboard is calculated with approximately 46% of the test data. The final results will be based on the other 54%, so the final standings may be different.

Then it all boils down to the method of split between public and private LB test sets. If it was random split. Then current scores can pretty much be the final result. If it was not random, and there was some other heuristic used to split the test set - we might be in for a surprise :)

And indeed, there may well be a shakeup. There are two types of shakeup; one is a score shakeup where the Public data and the Private data distributions are very different, and people who have actively fitted to the Public score will suffer. However, there is also a positional shakeup (which is what I think will happen here): The Public and Private splits are statistically similar, but eventually all of the LB scores become compacted in a very narrow range (say for example everyone has a Public score of 0.95 +/- 0.01) then the slightest variation in the last significant figure can make a huge difference to ones final standing.
